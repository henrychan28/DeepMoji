{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/pb_group/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import example_helper\n",
    "import json\n",
    "from deepmoji.model_def import deepmoji_transfer\n",
    "from deepmoji.global_variables import PRETRAINED_PATH\n",
    "from deepmoji.finetuning import (\n",
    "    load_benchmark,\n",
    "    finetune)\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batchsize_maxlen(texts):\n",
    "    \"\"\" Calculates the maximum length in the provided texts and a suitable\n",
    "        batch size. Rounds up maxlen to the nearest multiple of ten.\n",
    "\n",
    "    # Arguments:\n",
    "        texts: List of inputs.\n",
    "\n",
    "    # Returns:\n",
    "        Batch size,\n",
    "        max length\n",
    "    \"\"\"\n",
    "    def roundup(x):\n",
    "        return int(math.ceil(x / 10.0)) * 10\n",
    "\n",
    "    # Calculate max length of sequences considered\n",
    "    # Adjust batch_size accordingly to prevent GPU overflow\n",
    "    lengths = [len(tokenize(t)) for t in texts]\n",
    "    maxlen = roundup(np.percentile(lengths, 80.0))\n",
    "    batch_size = 250 if maxlen <= 100 else 50\n",
    "    return batch_size, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for embedding\n",
      "Loading weights for bi_lstm_0\n",
      "Loading weights for bi_lstm_1\n",
      "Loading weights for attlayer\n",
      "Ignoring weights for softmax\n",
      "Method:  last\n",
      "Metric:  acc\n",
      "Classes: 6\n",
      "Trainable weights: [<tf.Variable 'bi_lstm_0_4/forward_lstm_9/kernel:0' shape=(256, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_0_4/forward_lstm_9/recurrent_kernel:0' shape=(512, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_0_4/forward_lstm_9/bias:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'bi_lstm_0_4/backward_lstm_9/kernel:0' shape=(256, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_0_4/backward_lstm_9/recurrent_kernel:0' shape=(512, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_0_4/backward_lstm_9/bias:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'bi_lstm_1_4/forward_lstm_10/kernel:0' shape=(1024, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_1_4/forward_lstm_10/recurrent_kernel:0' shape=(512, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_1_4/forward_lstm_10/bias:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'bi_lstm_1_4/backward_lstm_10/kernel:0' shape=(1024, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_1_4/backward_lstm_10/recurrent_kernel:0' shape=(512, 2048) dtype=float32_ref>, <tf.Variable 'bi_lstm_1_4/backward_lstm_10/bias:0' shape=(2048,) dtype=float32_ref>, <tf.Variable 'softmax_4/kernel:0' shape=(2304, 6) dtype=float32_ref>, <tf.Variable 'softmax_4/bias:0' shape=(6,) dtype=float32_ref>]\n",
      "Training..\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '../data/Six-Emotion/raw-balance.pickle'\n",
    "nb_classes = 6\n",
    "with open('../model/vocabulary.json', 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "data = load_benchmark(DATASET_PATH, vocab)\n",
    "\n",
    "model = deepmoji_transfer(nb_classes, data['maxlen'], PRETRAINED_PATH)\n",
    "#model.summary()\n",
    "model, acc = finetune(model, data['texts'], data['labels'], nb_classes,\n",
    "                      data['batch_size'], method='last')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hahahahahaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_PATH, 'r') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['info', 'texts', 'val_ind', 'test_ind', 'train_ind']\n",
      "<type 'unicode'>\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(type(data['texts'][0]))\n",
    "print(type(data['val_ind']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['info'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
